// @generated by Cursor AI (Claude) ‚Äî verified by Kevin

import { useState, useEffect, useCallback, useRef } from 'react';
import { GoogleGenAI } from '@google/genai';
import geminiConfig from '@/config/gemini';

/**
 * Custom Hook pour la synth√®se vocale avec Gemini TTS
 * 
 * Utilise l'API Gemini TTS pour convertir du texte en parole avec des voix naturelles.
 * Remplace le Web Speech API par Gemini pour une meilleure qualit√© vocale.
 * 
 * Fonctionnalit√©s :
 * - Parler un texte avec une voix Gemini configur√©e
 * - Arr√™ter la parole en cours
 * - G√©rer les erreurs (API non disponible, erreurs r√©seau)
 * - D√©tecter quand la parole est termin√©e
 * - Support multilingue (FR, Wolof)
 * 
 * @param {Object} [options] - Options du hook
 * @param {string} [options.language='fr-FR'] - Langue de la voix
 * @param {string} [options.voiceName='Kore'] - Nom de la voix Gemini (voir docs pour les 30 voix disponibles)
 * 
 * @returns {Object} √âtat et fonctions de synth√®se vocale
 * @property {boolean} isSpeaking - true si la synth√®se vocale est en cours
 * @property {boolean} isSupported - true si Gemini TTS est disponible
 * @property {Object|null} error - Erreur √©ventuelle
 * @property {function} speak - Parler un texte
 * @property {function} stop - Arr√™ter la parole en cours
 * 
 * @example
 * const { speak, stop, isSpeaking, isSupported } = useGeminiTextToSpeech({ language: 'fr-FR', voiceName: 'Kore' });
 * 
 * // Parler un texte
 * speak("Bonjour ! Je vais vous aider √† cr√©er votre compte.");
 * 
 * // Arr√™ter
 * if (isSpeaking) {
 *   stop();
 * }
 */
export function useGeminiTextToSpeech(options = {}) {
  const {
    language = 'fr-FR',
    voiceName = 'Kore', // Voix par d√©faut : Kore (ferme, professionnelle)
  } = options;

  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isSupported, setIsSupported] = useState(false);
  const [isGenerating, setIsGenerating] = useState(false); // √âtat pour la g√©n√©ration audio
  const [error, setError] = useState(null);

  const audioContextRef = useRef(null);
  const audioSourceRef = useRef(null);
  const onEndCallbackRef = useRef(null);
  const onStartCallbackRef = useRef(null);
  const geminiClientRef = useRef(null);

  /**
   * Initialiser le client Gemini et v√©rifier la disponibilit√©
   */
  useEffect(() => {
    console.log('üîß Initialisation Gemini TTS...', {
      enabled: geminiConfig.enabled,
      hasApiKey: !!geminiConfig.apiKey,
      apiKeyLength: geminiConfig.apiKey?.length || 0,
    });

    if (!geminiConfig.enabled || !geminiConfig.apiKey) {
      console.warn('‚ö†Ô∏è Gemini TTS non configur√©:', {
        enabled: geminiConfig.enabled,
        hasApiKey: !!geminiConfig.apiKey,
      });
      setIsSupported(false);
      setError({
        code: 'NOT_SUPPORTED',
        message: 'Gemini TTS n\'est pas configur√©. V√©rifiez VITE_GEMINI_API_KEY dans .env.local',
      });
      return;
    }

    try {
      // Dans le navigateur, GoogleGenAI attend un objet avec apiKey
      geminiClientRef.current = new GoogleGenAI({ apiKey: geminiConfig.apiKey });
      setIsSupported(true);
      setError(null);
      console.log('‚úÖ Gemini TTS initialis√© avec succ√®s');
    } catch (err) {
      console.error('‚ùå Erreur initialisation Gemini TTS:', err);
      setIsSupported(false);
      setError({
        code: 'INIT_ERROR',
        message: 'Erreur lors de l\'initialisation de Gemini TTS',
        originalError: err,
      });
    }
  }, []);

  /**
   * Cr√©er un AudioContext pour jouer l'audio
   */
  const getAudioContext = useCallback(() => {
    if (!audioContextRef.current) {
      const AudioContextClass = window.AudioContext || window.webkitAudioContext;
      if (AudioContextClass) {
        audioContextRef.current = new AudioContextClass();
      }
    }
    return audioContextRef.current;
  }, []);

  /**
   * Convertir les donn√©es PCM en AudioBuffer et les jouer
   */
  const playAudioBuffer = useCallback(async (pcmData, onEnd, onStart) => {
    try {
      const audioContext = getAudioContext();
      if (!audioContext) {
        throw new Error('AudioContext non disponible');
      }

      // Les donn√©es PCM de Gemini sont en format 24kHz, 16-bit, mono
      const sampleRate = 24000;
      const channels = 1;
      const sampleWidth = 2; // 16-bit = 2 bytes

      // Cr√©er un AudioBuffer
      const frameCount = pcmData.length / sampleWidth;
      const audioBuffer = audioContext.createBuffer(channels, frameCount, sampleRate);

      // Convertir les donn√©es PCM (Int16Array) en Float32Array pour Web Audio API
      const channelData = audioBuffer.getChannelData(0);
      
      // Cr√©er un DataView pour lire les donn√©es Int16 (little-endian)
      const dataView = new DataView(pcmData.buffer, pcmData.byteOffset, pcmData.length);

      for (let i = 0; i < frameCount; i++) {
        // Lire un Int16 (little-endian) depuis les donn√©es PCM
        const int16Value = dataView.getInt16(i * sampleWidth, true); // true = little-endian
        // Convertir Int16 (-32768 √† 32767) en Float32 (-1.0 √† 1.0)
        channelData[i] = int16Value / 32768.0;
      }

      // Cr√©er une source audio
      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);

      // Stocker la r√©f√©rence pour pouvoir l'arr√™ter
      audioSourceRef.current = source;

      // G√©rer les √©v√©nements
      source.onended = () => {
        setIsSpeaking(false);
        audioSourceRef.current = null;
        console.log('‚úÖ Synth√®se vocale Gemini termin√©e');

        if (onEndCallbackRef.current) {
          onEndCallbackRef.current();
          onEndCallbackRef.current = null;
        }
        onStartCallbackRef.current = null;
      };

      // Appeler onStart avant de jouer
      if (onStartCallbackRef.current) {
        onStartCallbackRef.current();
        onStartCallbackRef.current = null;
      }

      // D√©marrer la lecture
      source.start(0);
      setIsSpeaking(true);
      console.log('üîä Synth√®se vocale Gemini d√©marr√©e');

    } catch (err) {
      console.error('‚ùå Erreur lecture audio:', err);
      setIsSpeaking(false);
      setError({
        code: 'AUDIO_PLAYBACK_ERROR',
        message: 'Erreur lors de la lecture de l\'audio',
        originalError: err,
      });

      if (onEndCallbackRef.current) {
        onEndCallbackRef.current();
        onEndCallbackRef.current = null;
      }
      onStartCallbackRef.current = null;
    }
  }, [getAudioContext]);

  /**
   * Parler un texte avec Gemini TTS
   * 
   * @param {string} text - Texte √† prononcer
   * @param {Object} [overrides] - Options √† surcharger (language, voiceName)
   * @param {Function} [onEnd] - Callback appel√© quand la parole est termin√©e
   * @param {Function} [onStart] - Callback appel√© quand la parole commence
   * 
   * @returns {Promise<void>}
   */
  const speak = useCallback(async (text, overrides = {}, onEnd = null, onStart = null) => {
    console.log('üì¢ Appel speak()', {
      text: text?.substring(0, 50) + '...',
      isSupported,
      hasClient: !!geminiClientRef.current,
    });

    if (!isSupported || !geminiClientRef.current) {
      console.error('‚ùå Gemini TTS non disponible:', {
        isSupported,
        hasClient: !!geminiClientRef.current,
      });
      setError({
        code: 'NOT_SUPPORTED',
        message: 'Gemini TTS n\'est pas disponible',
      });
      return;
    }

    if (!text || typeof text !== 'string' || text.trim() === '') {
      setError({
        code: 'INVALID_TEXT',
        message: 'Le texte √† prononcer ne peut pas √™tre vide',
      });
      return;
    }

    try {
      // Arr√™ter toute parole en cours
      stop();

      // Stocker les callbacks
      onEndCallbackRef.current = onEnd;
      onStartCallbackRef.current = onStart;

      setError(null);

      const client = geminiClientRef.current;
      const finalVoiceName = overrides.voiceName || voiceName;
      const finalLanguage = overrides.language || language;

      console.log('üé§ G√©n√©ration audio Gemini TTS:', {
        text: text.substring(0, 50) + '...',
        voice: finalVoiceName,
        language: finalLanguage,
      });

      // Indiquer que la g√©n√©ration est en cours
      setIsGenerating(true);
      const generationStartTime = Date.now();

      // Appeler Gemini TTS API
      const response = await client.models.generateContent({
        model: 'gemini-2.5-flash-preview-tts', // Mod√®le TTS Gemini
        contents: [{ parts: [{ text: text }] }],
        config: {
          responseModalities: ['AUDIO'],
          speechConfig: {
            voiceConfig: {
              prebuiltVoiceConfig: { voiceName: finalVoiceName },
            },
          },
        },
      });

      // Calculer le temps de g√©n√©ration
      const generationTime = Date.now() - generationStartTime;
      console.log(`‚è±Ô∏è G√©n√©ration audio termin√©e en ${generationTime}ms`);

      // Extraire les donn√©es audio
      const audioData = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
      
      if (!audioData) {
        console.error('‚ùå Structure de r√©ponse inattendue:', JSON.stringify(response, null, 2));
        setIsGenerating(false);
        throw new Error('Aucune donn√©e audio retourn√©e par Gemini TTS. V√©rifiez la structure de la r√©ponse.');
      }
      
      console.log('‚úÖ Donn√©es audio re√ßues:', {
        dataLength: audioData.length,
        generationTime: `${generationTime}ms`,
      });

      // La g√©n√©ration est termin√©e, on va maintenant jouer l'audio
      setIsGenerating(false);

      // Convertir les donn√©es base64 en ArrayBuffer (navigateur)
      const binaryString = atob(audioData);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }

      // Jouer l'audio
      await playAudioBuffer(bytes, onEnd, onStart);

    } catch (err) {
      console.error('‚ùå Erreur synth√®se vocale Gemini:', err);
      setIsSpeaking(false);
      setIsGenerating(false);
      setError({
        code: 'SPEECH_ERROR',
        message: err.message || 'Erreur lors de la synth√®se vocale Gemini',
        originalError: err,
      });

      if (onEndCallbackRef.current) {
        onEndCallbackRef.current();
        onEndCallbackRef.current = null;
      }
      onStartCallbackRef.current = null;
    }
  }, [isSupported, voiceName, language, playAudioBuffer]);

  /**
   * Arr√™ter la parole en cours
   */
  const stop = useCallback(() => {
    if (audioSourceRef.current) {
      try {
        audioSourceRef.current.stop();
        audioSourceRef.current = null;
      } catch (err) {
        // Ignorer les erreurs si la source est d√©j√† arr√™t√©e
      }
    }

    setIsSpeaking(false);
    onEndCallbackRef.current = null;
    onStartCallbackRef.current = null;
    console.log('‚èπÔ∏è Synth√®se vocale Gemini arr√™t√©e');
  }, []);

  /**
   * Nettoyer lors du d√©montage
   */
  useEffect(() => {
    return () => {
      stop();
      if (audioContextRef.current) {
        audioContextRef.current.close().catch(() => {});
      }
    };
  }, [stop]);

  return {
    isSpeaking,
    isGenerating, // Nouvel √©tat : g√©n√©ration en cours
    isSupported,
    error,
    speak,
    stop,
    // Note: pause et resume ne sont pas support√©s par Gemini TTS
    pause: () => {}, // Pas de pause pour Gemini TTS
    resume: () => {}, // Pas de resume pour Gemini TTS
  };
}

export default useGeminiTextToSpeech;

